import re
import unicodedata
import transliterate as tr
from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score

UNK_CHAR = 'üÜí'

def strip_accents(s):
   return ''.join(c for c in unicodedata.normalize('NFD', s)
                  if unicodedata.category(c) != 'Mn')

conv = {
    # consonants
    '‡§ï': 'k', '‡§ñ': 'kh', '‡§ó': 'g', '‡§ò': 'gh', '‡§ô': '·πÖ', 
    '‡§ö': 'c', '‡§õ': 'ch', '‡§ú': 'j', '‡§ù': 'jh', '‡§û': '√±', 
    '‡§ü': '·π≠', '‡§†': '·π≠h', '‡§°': '·∏ç', '‡§¢': '·∏çh', '‡§£': '·πá',
    '‡§§': 't', '‡§•': 'th', '‡§¶': 'd', '‡§ß': 'dh', '‡§®': 'n',
    '‡§™': 'p', '‡§´': 'ph', '‡§¨': 'b', '‡§≠': 'bh', '‡§Æ': 'm', 
    '‡§Ø': 'y', '‡§∞': 'r', '‡§≤': 'l', '‡§µ': 'v', '‡§≥': '·∏∑',
    '‡§∂': '≈õ', '‡§∑': '·π£', '‡§∏': 's', '‡§π': 'h',
    '‡§ï‡§º': 'q', '‡§ñ‡§º': 'x', '‡§ó‡§º': 'ƒ°', '‡§¥': '·∏ª',
    '‡§ú‡§º': 'z', '‡§∑‡§º': '·∏ª', '‡§ù‡§º': '≈æ', '‡§°‡§º': '·πõ', '‡§¢‡§º': '·πõh',
    '‡§´‡§º': 'f', '‡§•‡§º': 'Œ∏', '‡§©': '·πâ', '‡§±': '·πü',

    # vowel diacritics
    '‡§ø': 'i', '‡•Å': 'u', '‡•á': 'e', '‡•ã': 'o',
    '‡•ä': '«í', '‡•Ü': 'ƒõ',
    '‡§æ': 'ƒÅ', '‡•Ä': 'ƒ´', '‡•Ç': '≈´', 
    '‡•É': '≈ï',
    '‡•à': 'ai', '‡•å': 'au',
    '‡•â': '≈è',
    '‡•Ö': 'ƒï',

    # vowel signs
    '‡§Ö': 'a', '‡§á': 'i', '‡§â': 'u', '‡§è': 'e', '‡§ì': 'o',
    '‡§Ü': 'ƒÅ', '‡§à': 'ƒ´', '‡§ä': '≈´', '‡§é': 'ƒõ', '‡§í': '«í',
    '‡§ã': '≈ï', 
    '‡§ê': 'ai', '‡§î': 'au', 
    '‡§ë': '≈è',
    '‡§ç': 'ƒï',
    
    '‡•ê': 'om',
    
    # chandrabindu
    '‡§Å': 'ÃÉ',
    
    # anusvara
    '‡§Ç': '·πÅ',
    
    # visarga
    '‡§É': '·∏•',
    
    # virama
    '‡•ç': '',
    
    # numerals
    '‡•¶': '0', '‡•ß': '1', '‡•®': '2', '‡•©': '3', '‡•™': '4',
    '‡•´': '5', '‡•¨': '6', '‡•≠': '7', '‡•Æ': '8', '‡•Ø': '9',
    
    # punctuation
    '‡•§': '.', # danda
    '‡••': '.', # double danda
    '+': '', # compound separator
    
    # abbreviation sign
    '‡•∞': '.',
}

conv_wikt = {
    'k': 'k', 'kh': 'kh', 'g': 'g', 'gh': 'gh', '·πÖ': 'ng',
    'c': 'c', 'ch': 'ch', 'j': 'j', 'jh': 'jh', '√±': 'n',
    '·π≠': 'tt', '·π≠h': 'tth', '·∏ç': 'dd', '·∏çh': 'ddh', '·πá': 'n',
    't': 't', 'th': 'th', 'd': 'd', 'dh': 'dh', 'n': 'n',
    'p': 'p', 'ph': 'ph', 'b': 'b', 'bh': 'bh', 'm': 'm',
    'y': 'y', 'r': 'r', 'l' : 'l', 'v': 'v', 'w': 'v',
    '≈õ': 'sh', '·π£': 'sh', 's': 's', 'h': 'h',

    'q': 'q', 'x': 'x', 'ƒ°': 'Gh', 'f': 'f', 'z': 'z', '≈æ': 'Zh',
    '·∏•': 'h', '≈õ': 'sh',

    '·πõ': 'rr', '·πõh': 'rrh',

    'a': 'a', 'ƒÅ': 'aa',
    'i': 'i', 'ƒ´': 'ii',
    'u': 'u', '≈´': 'uu',
    'e': 'e', 'ai': 'E',
    'o': 'o', 'au': 'O',
    '≈è': 'O',

    '¬∑': '', '~': '~',
}

nasal_assim = {
    '‡§ï': '‡§ô', '‡§ñ': '‡§ô', '‡§ó': '‡§ô', '‡§ò': '‡§ô', 
    '‡§ö': '‡§û', '‡§õ': '‡§û', '‡§ú': '‡§û', '‡§ù': '‡§û',  
    '‡§ü': '‡§£', '‡§†': '‡§£', '‡§°': '‡§£', '‡§¢': '‡§£',
    '‡§™': '‡§Æ', '‡§´': '‡§Æ', '‡§¨': '‡§Æ', '‡§≠': '‡§Æ', '‡§Æ': '‡§Æ',
    '‡§µ': '‡§Å', '‡§Ø': '‡§Å', '‡§∑': '‡§®', '‡§∂': '‡§®', '‡§∏': '‡§®'
}

perm_cl = {
    '‡§Æ‡•ç‡§≤': True, '‡§µ‡•ç‡§≤': True, '‡§®‡•ç‡§≤': True,	
}

all_cons, special_cons = '‡§ï‡§ñ‡§ó‡§ò‡§ô‡§ö‡§õ‡§ú‡§ù‡§û‡§ü‡§†‡§°‡§¢‡§§‡§•‡§¶‡§ß‡§™‡§´‡§¨‡§≠‡§∂‡§∑‡§∏‡§Ø‡§∞‡§≤‡§µ‡§π‡§£‡§®‡§Æ', '‡§Ø‡§∞‡§≤‡§µ‡§π‡§®‡§Æ'
vowel, vowel_sign = 'a‡§ø‡•Å‡•É‡•á‡•ã‡§æ‡•Ä‡•Ç‡•à‡•å‡•â‡•Ö‡•Ü‡•ä', '‡§Ö‡§á‡§â‡§è‡§ì‡§Ü‡§à‡§ä‡§ã‡§ê‡§î‡§ë‡§ç'
syncope_pattern = r'([' + vowel + vowel_sign + r'])(‡§º?[' + all_cons + r'])a(‡§º?[' + all_cons.replace("‡§Ø", "") + r'])([‡§Ç‡§Å]?[' + vowel + vowel_sign + r'])'

def magic(x):
    return (((re.search(r'[' + special_cons + ']', x.group(1)) and re.search(r'‡•ç', x.group(2))
        and not ((x.group(2) + x.group(3) + x.group(4)) in perm_cl))
        or re.search(r'‡§Ø[‡•Ä‡•á‡•à]', x.group(2) + x.group(3)))
        and 'a' or '') + x.group(1) + x.group(2) + x.group(3) + x.group(4)
    

def translit(text):
    # adds inherent schwas wherever they are possible
    text = unicodedata.normalize('NFD', text)
    text = re.sub('([' + all_cons + ']‡§º?)([' + vowel + '‡•ç]?)',
        lambda x: x.group(1) + ('a' if x.group(2) == "" else x.group(2)), text)
    for word in re.findall(r"[‡§Ä-‡•øa]+", text):
        orig_word = word
        word = word[::-1]
        word = re.sub(r'^a(‡§º?)([' + all_cons + r'])(.)(.?)', magic, word)
        while re.search(syncope_pattern, word):
            word = re.sub(syncope_pattern, r'\1\2\3\4', word)
        word = re.sub(r'(.?)‡§Ç(.)', lambda x:
            x.group(1) + (x.group(1) + x.group(2) == "a" and "‡•ç‡§Æ" or 
            (x.group(1) == "" and re.search(r'[' + vowel + r']', x.group(2)) and "ÃÉ" or (nasal_assim[x.group(1)] if x.group(1) in nasal_assim else "n"))) + x.group(2), word)
        text = re.sub(orig_word, word[::-1], text)
    text = re.sub(r'.‡§º?', lambda x: conv[x.group(0)] if x.group(0) in conv else x.group(0), text)
    text = re.sub(r'a([iu])ÃÉ', r'aÕ†\1', text)
    text = re.sub(r'j√±', r'gy', text)
    text = re.sub(r'√±z', r'nz', text)
    return text

# converts from the Wiktionary translit scheme to our scheme
def convert(pron):
    pron = pron.replace('≈ï', 'ri')
    temp = ""
    for char in pron:
        if 'TILDE' in unicodedata.name(char):
            temp += strip_accents(char) + '~'
        else:
            temp += char
    pron = temp

    res = []
    i = 0
    l = len(pron)
    while i != l:
        for j in range(min(l - 1, i + 1), i - 1, -1):
            if pron[i:j + 1] in conv_wikt:
                res.append(conv_wikt[pron[i:j + 1]])
                i = j + 1
                break
        else:
            res.append(pron[i])
            i += 1
    return res

def force_align(ortho, phon):
    # two pointer technique, compares in linear time
    i, j = 0, 0
    n, m = len(ortho), len(phon)
    res = []
    while i < n:
        if j >= m:
            res.append([True, False])
            i += 1
        elif ortho[i] == phon[j]:
            if ortho[i] == 'a': res.append([True, True])
            i += 1
            j += 1
        elif phon[j] == 'a':
            res.append([False, True])
            j += 1
        elif ortho[i] == 'a':
            res.append([True, False])
            i += 1
        elif ortho[i] in [UNK_CHAR, '-']:
            i += 1
        else:
            raise Exception('Unable to force-align {}, phon {}\nCompare {} and {}'.format(ortho, phon, ortho[i], phon[j]))
    
    return res

if __name__ == "__main__":
    X, Y = [], []
    bad, total = 0, 0
    with open('../data/extra_large.csv', 'r') as fin:
        # fout.write("Word,Translit,Normalized\n")
        for i, line in enumerate(fin):
            if i == 0: continue
            try:
                word, phon = line.strip().split(',')
                trans = tr.transliterate(word)
                con = convert(translit(word))
                phon = phon.replace('@', '')
                print(word, ''.join(trans), phon.replace(' ', ''), ''.join(con))
                res = [x[1] for x in force_align(trans, phon.split())]
                res2 = [x[1] for x in force_align(trans, con)]
                good = True
                for a, b in zip(res, res2):
                    X.append(a)
                    Y.append(b)
                    if a != b:
                        good = False
                if not good: bad += 1
                total += 1
            except Exception as e:
                print(e)
                continue
    print(f"Word Accuracy: {1 - bad/total}")
    print(f"Accuracy: {accuracy_score(X, Y)}\nRecall: {recall_score(X, Y)}\nPrecision: {precision_score(X, Y)}")
    
    